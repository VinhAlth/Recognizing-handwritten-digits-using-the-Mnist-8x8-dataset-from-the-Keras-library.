{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMhGR9YqMC_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bfba780-04e1-4fb2-c5a2-e3655a8e6915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO loading MNIST (sample dataset...)\n",
            "data before: [[ 0.  0.  5. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ... 10.  0.  0.]\n",
            " [ 0.  0.  0. ... 16.  9.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ...  6.  0.  0.]\n",
            " [ 0.  0.  2. ... 12.  0.  0.]\n",
            " [ 0.  0. 10. ... 12.  1.  0.]]\n",
            "norm data: [[0.     0.     0.3125 ... 0.     0.     0.    ]\n",
            " [0.     0.     0.     ... 0.625  0.     0.    ]\n",
            " [0.     0.     0.     ... 1.     0.5625 0.    ]\n",
            " ...\n",
            " [0.     0.     0.0625 ... 0.375  0.     0.    ]\n",
            " [0.     0.     0.125  ... 0.75   0.     0.    ]\n",
            " [0.     0.     0.625  ... 0.75   0.0625 0.    ]]\n",
            "[INFO] sample: 1797, dim: 64\n",
            "[INFO] training network...\n",
            "[INFO] epoch=1, loss=609.0736953\n",
            "[INFO] epoch=100, loss=20.2391961\n",
            "[INFO] epoch=200, loss=3.2125533\n",
            "[INFO] epoch=300, loss=1.7211749\n",
            "[INFO] epoch=400, loss=1.4333604\n",
            "[INFO] epoch=500, loss=1.3067750\n",
            "[INFO] epoch=600, loss=1.2358314\n",
            "[INFO] epoch=700, loss=1.1906102\n",
            "[INFO] epoch=800, loss=1.1593300\n",
            "[INFO] epoch=900, loss=1.1363993\n",
            "[INFO] epoch=1000, loss=1.1187800\n",
            "[INFO] evaluating network...\n",
            "[[0.     0.0625 0.75   ... 0.3125 0.     0.    ]\n",
            " [0.     0.     0.     ... 0.     0.     0.    ]\n",
            " [0.     0.0625 0.6875 ... 0.5    0.     0.    ]\n",
            " ...\n",
            " [0.     0.     0.     ... 0.75   0.     0.    ]\n",
            " [0.     0.     0.     ... 1.     0.625  0.    ]\n",
            " [0.     0.     0.375  ... 0.25   0.     0.    ]]\n",
            "<class 'numpy.ndarray'>\n",
            "(450, 64)\n",
            "(450, 10)\n",
            "<class 'numpy.ndarray'>\n",
            "prediction [5 4 3 6 3 4 0 7 2 2 4 2 0 5 1 2 2 7 4 0 3 6 9 1 3 5 3 3 4 5 1 1 1 1 0 8 1\n",
            " 6 5 0 0 3 5 2 5 7 2 9 8 5 9 8 6 5 3 9 7 7 8 1 6 9 1 6 1 9 1 6 1 6 5 1 1 3\n",
            " 9 6 0 4 4 7 2 1 1 7 5 9 3 4 8 9 3 2 8 9 7 7 0 8 5 2 2 2 4 9 3 4 1 3 4 4 8\n",
            " 9 4 9 7 9 4 2 1 7 4 1 1 0 6 3 6 2 6 5 1 4 5 3 1 9 3 8 1 6 7 7 2 2 0 1 3 8\n",
            " 1 4 6 5 1 7 0 2 5 5 4 0 1 4 4 5 1 0 3 1 2 5 8 1 8 9 9 7 7 7 3 1 3 9 8 8 4\n",
            " 5 2 2 4 2 3 6 0 0 1 3 4 2 5 1 2 2 7 7 6 3 4 4 6 5 5 4 5 9 9 1 4 3 4 3 6 9\n",
            " 9 9 3 9 4 1 0 0 5 6 9 5 2 3 1 2 1 1 2 0 4 0 1 3 0 8 9 5 6 7 4 7 9 1 9 2 7\n",
            " 8 0 8 0 7 2 5 3 1 3 9 6 1 8 2 6 9 2 3 0 1 3 6 2 6 0 0 1 8 8 4 2 2 1 9 9 3\n",
            " 0 9 8 2 5 0 7 6 7 3 8 5 4 8 9 5 5 9 7 9 9 1 5 9 8 2 4 6 2 6 4 3 2 3 7 8 2\n",
            " 4 4 0 2 5 7 4 1 3 4 6 4 2 7 4 9 5 2 0 8 9 3 7 2 4 5 0 6 0 3 3 1 1 8 5 3 6\n",
            " 5 9 3 8 2 7 5 0 4 6 3 1 3 7 3 1 0 2 9 0 9 0 4 7 6 8 2 1 7 3 6 6 2 0 3 6 5\n",
            " 8 6 8 4 7 2 1 7 2 7 0 2 8 4 8 8 7 2 8 6 1 8 8 1 2 0 3 6 9 5 1 4 5 0 4 6 8\n",
            " 3 6 9 0 6 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        40\n",
            "           1       0.91      0.98      0.94        52\n",
            "           2       1.00      1.00      1.00        52\n",
            "           3       0.96      0.96      0.96        50\n",
            "           4       1.00      0.94      0.97        51\n",
            "           5       0.98      1.00      0.99        41\n",
            "           6       1.00      1.00      1.00        41\n",
            "           7       1.00      1.00      1.00        38\n",
            "           8       0.97      0.90      0.94        41\n",
            "           9       0.91      0.93      0.92        44\n",
            "\n",
            "    accuracy                           0.97       450\n",
            "   macro avg       0.97      0.97      0.97       450\n",
            "weighted avg       0.97      0.97      0.97       450\n",
            "\n",
            "[INFO] predict network...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Định dạng danh sách giá trị ảnh 8x8 thành mảng NumPy một chiều\\nimg = [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]\\nimg = np.array(img)\\n\\n# In thông tin ảnh và dự đoán\\nprint(\"[INFO] predict network...\")\\nprint(img)\\nprint(img.shape)  # In kích thước của ảnh\\n# Nếu bạn đã tạo và đào tạo mô hình trước đó (nn) thì bạn có thể tiến hành dự đoán như sau:\\n# prediction = nn.predict(img.reshape(1, 64))  # Định dạng ảnh thành mảng (1, 64)\\n# print(prediction.argmax(axis=1))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "import numpy as np\n",
        "#LABELING\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "#TRAIN AND TEST DATASET\n",
        "from sklearn.model_selection import train_test_split\n",
        "#EVAL\n",
        "from sklearn.metrics import classification_report\n",
        "#DATASET\n",
        "from sklearn import datasets\n",
        "#Image processing\n",
        "import cv2\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, layers, alpha=0.1):\n",
        "        self.W = []\n",
        "        self.layers = layers\n",
        "        self.alpha = alpha\n",
        "        #len layers - 2 to remove in input and output layer\n",
        "        for i in np.arange(0,len(layers) - 2):\n",
        "            #get random number\n",
        "            w = np.random.rand(layers[i] + 1, layers[i+1] + 1)\n",
        "            # add to W list\n",
        "            self.W.append(w/np.sqrt(layers[i]))\n",
        "        w = np.random.rand(layers[-2] + 1, layers[-1])\n",
        "        self.W.append(w/np.sqrt(layers[-2]))\n",
        "\n",
        "    #Actiovation funciton for backpropagation\n",
        "        # sigmoid\n",
        "    def sigmoid(self, x):\n",
        "        return 1.0/(1 + np.exp(-x))\n",
        "    def sigmoid_deriv(self, x):\n",
        "        return x*(1-x)\n",
        "        #Softmax\n",
        "    def softmax(self, x):\n",
        "        return np.exp(x)/np.sum(np.exp(x), axis=1, keepdims=True)\n",
        "    def softmax_deriv(self, x):\n",
        "        return x*(1-x)\n",
        "        #tanh\n",
        "    def tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "    def tanh_deriv(self, x):\n",
        "        return 1.0 - np.tanh(x)**2\n",
        "    def fit(self, X, y, epochs=1000, displayUpdate=100):\n",
        "        #Add one\n",
        "        X = np.c_[X, np.ones((X.shape[0]))]\n",
        "        for epoch in np.arange(0, epochs):\n",
        "            for (x, target) in zip(X, y):\n",
        "                self.fit_partial(x, target)\n",
        "            if epoch == 0 or (epoch + 1) % displayUpdate == 0:\n",
        "                loss = self.calculate_loss(X, y)\n",
        "                print(\"[INFO] epoch={}, loss={:.7f}\".format(epoch + 1, loss))\n",
        "    def fit_partial(self, x, y):\n",
        "        #convert to 2D\n",
        "        A = [np.atleast_2d(x)]\n",
        "        #FEEDFORWARD\n",
        "        for layer in np.arange(0, len(self.W)):\n",
        "            net = A[layer].dot(self.W[layer])\n",
        "            #if ask to change activation function, change below this\n",
        "            out = self.sigmoid(net)\n",
        "            A.append(out)\n",
        "        error = A[-1] - y\n",
        "        D = [error*self.sigmoid_deriv(A[-1])]\n",
        "        #BACKPROPAGATION\n",
        "        for layer in np.arange(len(A) - 2, 0, -1):\n",
        "            delta = D[-1].dot(self.W[layer].T)\n",
        "            delta = delta*self.sigmoid_deriv(A[layer])\n",
        "            D.append(delta)\n",
        "        D = D[::-1]\n",
        "        for layer in np.arange(0, len(self.W)):\n",
        "            self.W[layer] += -self.alpha * A[layer].T.dot(D[layer])\n",
        "    def predict(self, X, addBias=True):\n",
        "        p = np.atleast_2d(X)\n",
        "        if addBias:\n",
        "            p = np.c_[p, np.ones((p.shape[0]))]\n",
        "        for layer in np.arange(0, len(self.W)):\n",
        "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
        "        return p\n",
        "    def calculate_loss(self, X, targets):\n",
        "        targets = np.atleast_2d(targets)\n",
        "        predictions = self.predict(X, addBias=False)\n",
        "        loss = 0.5 * np.sum((predictions - targets) ** 2)\n",
        "        return loss\n",
        "    def save_weights(self, filename):\n",
        "        np.save(filename, *self.W)\n",
        "    def load_weights(self, filename):\n",
        "        self.W = np.load(filename)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "#XOR\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "# Call NN class\n",
        "nn = NeuralNetwork([2,2,1], alpha=0.5)\n",
        "#train for XOR\n",
        "nn.fit(X, y, epochs=20000)\n",
        "for (x, target) in zip(X, y):\n",
        "    pred = nn.predict(x)[0][0]\n",
        "    step = 1 if pred > 0.5 else 0\n",
        "    print(\"[INFO] data={}, ground-truth={}, pred={:.4f}, step={}\".format(x, target[0], pred, step))\n",
        "\"\"\"\n",
        "\n",
        "#MNIST dataset\n",
        "print(\"INFO loading MNIST (sample dataset...)\")\n",
        "#load datas\n",
        "digits = datasets.load_digits()\n",
        "data = digits.data.astype(\"float\")\n",
        "print(\"data before:\" , data)\n",
        "#normalize\n",
        "data = (data - data.min())/(data.max() - data.min())\n",
        "print(\"norm data:\", data)\n",
        "print(\"[INFO] sample: {}, dim: {}\".format(data.shape[0], data.shape[1]))\n",
        "#split train and test\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, digits.target, test_size=0.25)\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "#init\n",
        "nn = NeuralNetwork([trainX.shape[1], 32, 16, 10])\n",
        "\n",
        "#train\n",
        "\n",
        "print(\"[INFO] training network...\")\n",
        "nn.fit(trainX, trainY, epochs=1000)\n",
        "#eval\n",
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "print(testX)\n",
        "print(type(testX))\n",
        "print(testX.shape)\n",
        "predictions = nn.predict(testX)\n",
        "print(predictions.shape)\n",
        "print(type(predictions))\n",
        "predictions = predictions.argmax(axis=1)\n",
        "print(\"prediction\", predictions)\n",
        "print(classification_report(testY.argmax(axis=1), predictions))\n",
        "\n",
        "#predict\n",
        "print(\"[INFO] predict network...\")\n",
        "\"\"\"\n",
        "# Định dạng danh sách giá trị ảnh 8x8 thành mảng NumPy một chiều\n",
        "img = [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
        "img = np.array(img)\n",
        "\n",
        "# In thông tin ảnh và dự đoán\n",
        "print(\"[INFO] predict network...\")\n",
        "print(img)\n",
        "print(img.shape)  # In kích thước của ảnh\n",
        "# Nếu bạn đã tạo và đào tạo mô hình trước đó (nn) thì bạn có thể tiến hành dự đoán như sau:\n",
        "# prediction = nn.predict(img.reshape(1, 64))  # Định dạng ảnh thành mảng (1, 64)\n",
        "# print(prediction.argmax(axis=1))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX)"
      ],
      "metadata": {
        "id": "E1idrud3Sfq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Mở ảnh JPEG\n",
        "image_path = '7777.jpg'  # Thay đổi đường dẫn tới ảnh của bạn\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Chuyển ảnh thành đen trắng (grayscale) và thay đổi kích thước thành 8x8\n",
        "image = image.convert(\"L\").resize((8, 8))\n",
        "\n",
        "# Chuyển ảnh thành mảng NumPy\n",
        "image_data = np.array(image)\n",
        "\n",
        "# Định dạng lại ảnh thành mảng (1, 64)\n",
        "image_data = image_data.reshape(1, 64)\n",
        "\n",
        "# Dự đoán số trên ảnh\n",
        "prediction = nn.predict(image_data)\n",
        "predicted_digit = prediction.argmax(axis=1)\n",
        "print(\"Predicted digit:\", predicted_digit[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "7MM8pXqWxMFa",
        "outputId": "9491b5c5-0188-4786-8a98-36593fe00377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8b70a1e31825>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Mở ảnh JPEG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'7777.jpg'\u001b[0m  \u001b[0;31m# Thay đổi đường dẫn tới ảnh của bạn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Chuyển ảnh thành đen trắng (grayscale) và thay đổi kích thước thành 8x8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '7777.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre = nn.predict(testX).argmax(axis=1)\n",
        "print(classification_report(testY.argmax(axis=1),pre))\n",
        "\n",
        "\n",
        "\n",
        "# Open the image using PIL\n",
        "image = Image.open('00.jpg')\n",
        "image = image.resize((8,8))\n",
        "# Convert the image to a NumPy array\n",
        "pixel_values = np.array(image)\n",
        "\n",
        "print(pixel_values)\n",
        "pixel_values = pixel_values.astype(\"float\")\n",
        "\n",
        "pixel_values = (pixel_values - pixel_values.min())/(pixel_values.max() - pixel_values.min())\n",
        "print(pixel_values)\n",
        "\n",
        "print(pixel_values.flatten())\n",
        "a = nn.predict(pixel_values.flatten()).argmax(axis=1)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "zyqLn_O0LUHh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}